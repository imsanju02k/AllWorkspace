<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title>How to easily deploy OpenShift on Azure using a GUI, Part 1</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/03/16/how-deploy-openshift-azure-gui-part-1" /><author><name>Ignacio Lago, Pablo Castelo</name></author><id>4d1ef3b6-2b6e-45da-8e1f-00d0c55938c3</id><updated>2023-03-16T07:00:00Z</updated><published>2023-03-16T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt; is a leading &lt;a href="https://developers.redhat.com/topics/containers"&gt;container&lt;/a&gt; application platform in building, deploying, and handling containerized applications at a large scale. The OpenShift tooling is built around the &lt;a href="https://developers.redhat.com/topics/gitops"&gt;GitOps&lt;/a&gt; approach for &lt;a href="http://developers.redhat.com/topics/ci-cd"&gt;continuous delivery&lt;/a&gt; using Git as a single source of truth for declarative infrastructure. All this can be achieved by using Red Hat OpenShift GitOps, Argo CD, and Red Hat Advanced Cluster Management for Kubernetes.&lt;/p&gt; &lt;p&gt;Deploying OpenShift on the Microsoft Azure Platform utilizing OpenShift GitOps makes it not only easier but enables you to achieve faster time to market, better collaboration, more efficient workflows, and ensures access to the cloud's scalability, flexibility, and reliability.&lt;/p&gt; &lt;p&gt;This is the first of two articles that demonstrates how to get your OpenShift cluster up and running in Azure quickly and easily without numerous failures in the process. This article demonstrates the steps to deploy OpenShift on Azure using the Red Hat Advanced Cluster Management. The following steps detail the prerequisites, setup, and deployment process utilizing a GUI.&lt;/p&gt; &lt;h2&gt;Step 1: Set up the prerequisites&lt;/h2&gt; &lt;p&gt;Follow these steps to configure Azure.&lt;/p&gt; &lt;p&gt;First, we have to be sure our quote is enough to deploy a Red Hat OpenShift Container Platform cluster.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Go to the &lt;a href="https://portal.azure.com"&gt;Azure Portal&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Click &lt;strong&gt;Subscription&lt;/strong&gt;. &lt;/li&gt; &lt;li&gt;Click &lt;strong&gt;Usage and Quotas &lt;/strong&gt;to filter using &lt;strong&gt;Region.&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;Locate the &lt;strong&gt;Standard DSv3 Family vCPUs &lt;/strong&gt;and&lt;strong&gt; &lt;/strong&gt;check the quota.&lt;/li&gt; &lt;li&gt;We need at least &lt;strong&gt;24 Cores&lt;/strong&gt; for a small cluster.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Second, we need a resource group containing a DNS zone to deploy the cluster.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Select &lt;strong&gt;Create Resource Group&lt;/strong&gt; and fill in the name and region. Then click &lt;strong&gt;Create&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;To create the DNS zone in the newly created resource group, select Create &lt;strong&gt;DNS_Zone &lt;/strong&gt;and&lt;strong&gt; Create&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Then select&lt;strong&gt; Fill_Name&lt;/strong&gt; and &lt;strong&gt;Create&lt;/strong&gt;.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Now we should have a &lt;strong&gt;Resource Group&lt;/strong&gt; with a DNS zone ready to use, as shown in Figure 1:&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/image_03.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/image_03.png?itok=ch92Q6wo" width="600" height="184" alt="The DNS zone in the newly created Resource Group." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: The DNS zone in the newly created Resource Group.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Step 2: Recover the Azure values&lt;/h2&gt; &lt;p&gt;We need to recover the credentials of the cloud provider, as shown in the following snippet:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;Your Azure environment details: Resource Group: openenv-5d9g3 DNS Zone: 5d9g3.azure.example.io Application: openenv-5d9g3 Application/Client/Service Principal ID: f4993d25-3cce-49f4-a68a-24bc1c166bd6 Password: 2Ci7Ba-boz.mK69c6m0wO5SLMtsuZpGUjy Tenant ID: example.onmicrosoft.com Subscription ID: 1d6c0f82-8e30-423a-9a1b-36fde35ab59c&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Step 3: Create additional resources (optional)&lt;/h2&gt; &lt;p&gt;We can also create resource groups for the virtual network/subnets and a network security group.&lt;/p&gt; &lt;p&gt;First, we create two resource groups for the networks and the cluster.&lt;/p&gt; &lt;p&gt;Create a resource group for the networks as follows:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Create &lt;strong&gt;Resource Group&lt;/strong&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;Fill in the &lt;strong&gt;Name and Region&lt;/strong&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;Click &lt;strong&gt;Create&lt;/strong&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;Inside the resource group, create a virtual network.  &lt;ul&gt;&lt;li aria-level="1"&gt;Fill in the name and select &lt;strong&gt;Create&lt;/strong&gt;.&lt;/li&gt; &lt;li aria-level="2"&gt;In the virtual network, select subnets from the left menu.&lt;/li&gt; &lt;li aria-level="2"&gt;Then select &lt;strong&gt;new subnet&lt;/strong&gt;.&lt;/li&gt; &lt;li aria-level="2"&gt;Fill in the name (masters) and select &lt;strong&gt;Create&lt;/strong&gt;.&lt;/li&gt; &lt;li aria-level="2"&gt;Repeat this process again for the workers' subnet.&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;Go back to the resource group to create a network security group. &lt;ul&gt;&lt;li aria-level="1"&gt;Fill in the name and select &lt;strong&gt;Create&lt;/strong&gt;.&lt;/li&gt; &lt;li aria-level="2"&gt;In the network security group, select &lt;strong&gt;Inbound Security Rules&lt;/strong&gt; in the left menu.&lt;/li&gt; &lt;li aria-level="2"&gt;Add a new one for port 80.&lt;/li&gt; &lt;li aria-level="2"&gt;Repeat this for these ports 443/6443/22623.&lt;/li&gt; &lt;li aria-level="2"&gt;In the network security group, select subnets in the left menu, then associate the workers subnet.&lt;/li&gt; &lt;li aria-level="2"&gt;Repeat this for the masters subnet.&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Create a resource group for the cluster as follows:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Create &lt;strong&gt;Resource Group&lt;/strong&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;Fill in the &lt;strong&gt;Name and Region.&lt;/strong&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;Select &lt;strong&gt;Create&lt;/strong&gt;.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Step 4: Install Red Hat Advanced Cluster Management via OpenShift GitOps&lt;/h2&gt; &lt;p&gt;Before installing the Red Hat Advanced Cluster Management operator, we need to deploy the ArgoCD first. We can do this by using this &lt;a href="https://github.com/ignaciolago/acm-ocp-azure"&gt;&lt;strong&gt;&lt;u&gt;repository&lt;/u&gt;&lt;/strong&gt;&lt;/a&gt;. Deploy the OpenShift GitOps ArgoCD by running the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;oc apply -k bootstrap/argocd&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Then install the Red Hat Advanced Cluster Management and integrate it with ArgoCD by running the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;oc apply -k bootstrap/deploy/00-applicationset-acm&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Step 5: Set up credentials for Azure via GUI&lt;/h2&gt; &lt;p&gt;Once we have those values, we need to create the credentials for the Azure network. We will set up the credential type, credential name, namespace, and cloud name with default values:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Credential Name = Azure&lt;/li&gt; &lt;li&gt;Namespace = Default&lt;/li&gt; &lt;li&gt;Base DNS domain = DNS Zone&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Click &lt;strong&gt;next&lt;/strong&gt; and then fill in the following values:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Client ID = Application/Client/Service Principal ID&lt;/li&gt; &lt;li aria-level="1"&gt;Client Secret = Password&lt;/li&gt; &lt;li aria-level="1"&gt;Subscription ID = Subscription ID&lt;/li&gt; &lt;li aria-level="1"&gt;Tenant ID = Tenant ID&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;We do not have to set any value for the proxy unless we have a customer proxy installation.&lt;/p&gt; &lt;p&gt;Now we need to &lt;a href="https://console.redhat.com/openshift/install/pull-secret"&gt;get the pull secret&lt;/a&gt; and keys. You can generate the keys using the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;ssh-keygen -t rsa&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Review the information for our credentials to use for the installation, as shown in Figure 2.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/image_04.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/image_04.png?itok=IzFijFBJ" width="600" height="498" alt="A screenshot the Azure credentials in the Review section." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2: Review the Azure credentials.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Step 6: Installing OpenShift cluster via the GUI&lt;/h2&gt; &lt;p&gt;We need to recover the following field:&lt;/p&gt; &lt;p&gt;DNS Zone = Base DNS Domain&lt;/p&gt; &lt;p&gt;We will establish the OpenShift release version, a name for the cluster, and a cluster set. We can create a new cluster set for all the Azure clusters or use the default.&lt;/p&gt; &lt;p&gt;The following description corresponds to the numbers in the screenshot of the Red Hat Advanced Cluster Management GUI in Figure 3:&lt;/p&gt; &lt;p&gt;We can also change the cluster resources by adding extra values using the Yaml view (1), and edit the configuration using the&lt;strong&gt; &lt;/strong&gt;deploy&lt;strong&gt; &lt;/strong&gt;(2)&lt;strong&gt; &lt;/strong&gt;cluster-install (3) buttons. For example, you can add custom resource groups containing the base DNS (4) or a virtual network (5) with two subnets for masters (6) and workers (7), network security group, and the cluster (8).&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/image_05.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/image_05.jpg?itok=oirtGcwu" width="600" height="514" alt="A closer look at the Openshift Avance Cluster Manager GUI and how to add extra values using the Yaml view." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 3: A closer look at the Red Hat Advance Cluster Management GUI and how to add extra values using the Yaml view.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Next, set up the &lt;strong&gt;Nodes Size&lt;/strong&gt; for the cluster and disk type (see Figure 4):&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/image_06.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/image_06.jpg?itok=eGQPGBN9" width="600" height="513" alt="Change the Disk Type and other values in the Cluster Details page of OpenShift Cluster Manager GUI." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 4: Change the Disk Type and other values.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;For networking, we have to define if we are going to use SDN or OVN and if we want to use custom values, as shown in the following snippet:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;Cluster network CIDR * : 10.128.0.0/14 Network host prefix * : 23 Service network CIDR * : 172.30.0.0/16 Machine CIDR * : 10.0.0.0/16&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;We will use default values for the proxy and automation.&lt;/p&gt; &lt;p&gt;Finally, you can review and install the cluster information as shown in Figure 5.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/image_07.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/image_07.png?itok=TRib6kCa" width="600" height="272" alt="Click on create cluster to view the logs." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 5: Click on create cluster to see the logs.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Deploying OpenShift on Azure is easy&lt;/h2&gt; &lt;p&gt;In this article, we demonstrated how to install an OpenShift cluster on Azure using a GUI. In the &lt;a href="https://developers.redhat.com/articles/2023/03/17/deploy-openshift-azure-gitops-part-2"&gt;next article&lt;/a&gt;, you will learn a different method for installing OpenShift on Azure utilizing GitOps. If you have questions, feel free to leave a comment below. Your feedback is welcome.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/03/16/how-deploy-openshift-azure-gui-part-1" title="How to easily deploy OpenShift on Azure using a GUI, Part 1"&gt;How to easily deploy OpenShift on Azure using a GUI, Part 1&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Ignacio Lago, Pablo Castelo</dc:creator><dc:date>2023-03-16T07:00:00Z</dc:date></entry><entry><title type="html">Quarkus 3.0.0.Alpha6 released</title><link rel="alternate" href="https://quarkus.io/blog/quarkus-3-0-0-alpha6-released/" /><author><name>Guillaume Smet</name></author><id>https://quarkus.io/blog/quarkus-3-0-0-alpha6-released/</id><updated>2023-03-15T00:00:00Z</updated><content type="html">A week after Alpha5, we are releasing Quarkus 3.0.0.Alpha6. While Alpha5 came with major changes such as the upgrade to Hibernate ORM 6, Alpha6 is a smaller release packed with bugfixes, enhancements, and improvements to our upgrade process. What’s new Among all the bugfixes and enhancements, two are worth mentioning...</content><dc:creator>Guillaume Smet</dc:creator></entry><entry><title type="html">Dashbuilder Quarkus Extension 0.27.0</title><link rel="alternate" href="https://blog.kie.org/2023/03/dashbuilder-quarkus-extension-0-27-0.html" /><author><name>William Siqueira</name></author><id>https://blog.kie.org/2023/03/dashbuilder-quarkus-extension-0-27-0.html</id><updated>2023-03-14T20:55:27Z</updated><content type="html">We are glad to announce that Dashbuilder Quarkus Extension 0.27.0 is out with multiple improvements. In this article we are going to share the new features and you can see a little about it on our Quarkus insights session: NEW SAMPLES SCREEN Dashbuilder now provides a new samples screen that will allow users to start from a sample dashboard to build their own. The Samples screen allows users to try a dashboard and add to their project if they want to. It will be only available in development mode, but they can be part of the final jar by setting the property quarkus.dashbuilder.include-samples to true.  By default the link to the samples screen is displayed only if users do not have dashboards. When the user has dashboards then the samples UI can be access from DEV UI: PROPERTIES It is possible to set a dashboard property using application.properties. If you have a property in dashboard you can set the value for that property using quarkus.dashbuilder.properties.{dashboard name}.{property name}=value Users can also declare quarkus properties in the dashboard. For example, the property quarkus.http.cors  can be read directly from the YAML dashboard by declaring a property with the same name. KIE TOOLS 0.27.0 RELEASE This version brings Dashbuilder 0.27.0 with VSCode extension release and many other improvements which you can see on the announcement post: INSTALLATION To install the latest version just update the dependency version to 0.27.0     &lt;dependency&gt;       &lt;groupId&gt;io.quarkiverse.dashbuilder&lt;/groupId&gt;       &lt;artifactId&gt;quarkus-dashbuilder&lt;/artifactId&gt;       &lt;version&gt;999-SNAPSHOT&lt;/version&gt;     &lt;/dependency&gt; CONCLUSION Dashbuilder Quarkus Extension 0.27.0 is out and you can try it right now! Stay tuned for new features and let us know if you have any questions. The post appeared first on .</content><dc:creator>William Siqueira</dc:creator></entry><entry><title>A tutorial on Middleware Automation Collections</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/03/14/tutorial-middleware-automation-collections" /><author><name>Harsha Cherukuri</name></author><id>3bba2083-ef20-4dd8-911f-81088d04cc6d</id><updated>2023-03-14T07:00:00Z</updated><published>2023-03-14T07:00:00Z</published><summary type="html">&lt;p&gt;Getting up to speed with &lt;a href="https://github.com/ansible-middleware"&gt;Ansible Middleware&lt;/a&gt; Collections &lt;span&gt;is easy, and installing the &lt;a href="https://developers.redhat.com/products/ansible/overview"&gt;Red Hat Ansible Automation Platform&lt;/a&gt; only requires a few steps. This tutorial demonstrates &lt;/span&gt;six steps to configure a WildFly instance using Ansible by&lt;span&gt; preparing a local machine with the necessary tooling and then deploying an instance of WildFly using the WildFly collection provided by the &lt;/span&gt;Ansible Middleware.&lt;/p&gt; &lt;h2&gt;Step 1: Install Ansible Automation Platform&lt;/h2&gt; &lt;p&gt;First, let’s get Ansible &lt;span&gt;Automation Platform &lt;/span&gt;installed on the control node. A control node is a machine from which we will push the configurations to the managed nodes/hosts. Managed nodes are the ones we would like to configure and they can be defined under inventory. You can install Ansible &lt;span&gt;Automation Platform&lt;/span&gt; using your preferred method. Refer to the &lt;a href="https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html#installation-guide"&gt;installing Ansible&lt;/a&gt; documentation for details.&lt;/p&gt; &lt;h2&gt;Step 2: Install the galaxy server&lt;/h2&gt; &lt;p&gt;Ansible Content Collections is a distribution format for content that can include playbooks, roles, modules, and plugins. By default, while installing collections using ansible-galaxy collection, we are referring to the &lt;a href="https://galaxy.ansible.com"&gt;Galaxy server&lt;/a&gt;. But we can configure a different galaxy server like the Ansible automation hub by providing the details of the server on ansible.cfg. You can follow the &lt;a href="https://docs.ansible.com/ansible/latest/galaxy/user_guide.html#downloading-a-collection-from-automation-hub"&gt;guide&lt;/a&gt; to do so. In this tutorial, we would be using the &lt;a href="https://galaxy.ansible.com"&gt;Galaxy server&lt;/a&gt; to install and configure using the &lt;a href="https://galaxy.ansible.com/middleware_automation/wildfly"&gt;middleware_automation.wildfly&lt;/a&gt; collection.&lt;/p&gt; &lt;h2&gt;Step 3: Installing the ansible-navigator utility&lt;/h2&gt; &lt;p&gt;We will use an &lt;a href="https://docs.ansible.com/automation-controller/latest/html/userguide/execution_environments.html"&gt;execution environment&lt;/a&gt; and the &lt;a href="https://ansible-navigator.readthedocs.io/en/latest/installation/#linux"&gt;ansible-navigator&lt;/a&gt; utility to perform the automation and provisioning of the WildFly instance. Install and configure ansible-navigator based on the documentation for your target operating system. To perform the execution of the automation, the &lt;a href="https://quay.io/repository/ansible-middleware/ansible-middleware-ee"&gt;ansible-middleware-ee&lt;/a&gt; execution environment provided by the team includes all of the Ansible Content Collections &lt;span&gt;and their dependencies. So there is no need to install any additional components on the control node. We would be using our execution environment as it already includes all of our latest collections so we don’t have to set it up again.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;Once ansible-navigator has been installed, execute the following command to browse all of the collections that are included within the execution environment image:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ansible-navigator --eei quay.io/ansible-middleware/ansible-middleware-ee:latest collections&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In the following output, we see the list of all the collections available in our execution environment.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt; Name Version Shadowed Type Path 0│ansible.builtin 2.12.5.post0 False contained /usr/local/lib/python3.8/site-packages/ansible 1│ansible.netcommon 3.0.0 False contained /usr/share/ansible/collections/ansible_collections/ansible 2│ansible.posix 1.4.0 False contained /usr/share/ansible/collections/ansible_collections/ansible 3│ansible.utils 2.6.1 False contained /usr/share/ansible/collections/ansible_collections/ansible 4│community.general 5.0.0 False contained /usr/share/ansible/collections/ansible_collections/communi 5│middleware_automation.amq 0.0.2 False contained /usr/share/ansible/collections/ansible_collections/middlew 6│middleware_automation.infinispan 1.0.3 False contained /usr/share/ansible/collections/ansible_collections/middlew 7│middleware_automation.jcliff 0.0.21 False contained /usr/share/ansible/collections/ansible_collections/middlew 8│middleware_automation.jws 0.0.3 False contained /usr/share/ansible/collections/ansible_collections/middlew 9│middleware_automation.keycloak 1.0.4 False contained /usr/share/ansible/collections/ansible_collections/middlew 10│middleware_automation.redhat_csp_download 1.2.2 False contained /usr/share/ansible/collections/ansible_collections/middlew 11│middleware_automation.wildfly 1.0.2 False contained /usr/share/ansible/collections/ansible_collections/middlew &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Step 4: Setting up the inventory&lt;/h2&gt; &lt;p&gt;Let's now set up a WildFly instance. Create an inventory file that includes a Red Hat Enterprise Linux 8 instance, the IP address of the instance, and login information for ansible to access it. We are using SSH keys instead of passwords. So these SSH keys are created on the controller node and we provide the path of the private key in the inventory file. Our inventory file looks like this:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;[wildfly] wildfly-0 ansible_host=10.0.148.43 ansible_user=root ansible_ssh_private_key_file=”path to your private key” &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Step 5: Installing and configuring WildFly&lt;/h2&gt; &lt;p&gt;Here is our Ansible Playbook &lt;code&gt;wildfly.yml&lt;/code&gt; for installing and configuring WildFly:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;--- - name: "Installation and configuration" hosts: wildfly vars: wildfly_install_workdir: '/opt' install_name: "wildfly" wildfly_user: "{{ install_name }}" wildfly_config_base: standalone-ha.xml wildfly_version: "26.0.0.Final" wildfly_home: "{{ wildfly_install_workdir }}/{{ install_name }}-{{ wildfly_version }}" collections: - middleware_automation.wildfly tasks: - name: Include wildfly role ansible.builtin.include_role: name: middleware_automation.wildfly.wildfly_install - name: "Set up for Wildfly instance" include_role: name: middleware_automation.wildfly.wildfly_systemd vars: wildfly_config_base: 'standalone-ha.xml' wildfly_basedir_prefix: "/opt/{{ install_name }}" wildfly_config_name: "{{ install_name }}" wildfly_instance_name: "{{ install_name }}" service_systemd_env_file: "/etc/{{ install_name }}.conf" service_systemd_conf_file: "/usr/lib/systemd/system/{{ install_name }}.service" &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Step 6: Run the Ansible Playbook&lt;/h2&gt; &lt;p&gt;Now, run the Ansible Playbook using ansible-navigator and the execution environment to configure WildFly on the remote node as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ansible-navigator --eei quay.io/ansible-middleware/ansible-middleware-ee:latest run wildfly.yml -i inventory -m stdout --become&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Once the playbook has completed executing, ssh into the instance and check the status and health check of the deployed WildFly service. We can do so with the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ssh root@10.0.148.43 curl http://127.0.0.1:9990/health &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following code snippet shows the output:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;[{"name" : "boot-errors", "outcome" : true},{"name" : "deployments-status", "outcome" : true},{"name" : "server-state", "outcome" : true, "data" : [{ "value" : "running" }]},{"name" : "live-server", "outcome" : true},{"name" : "started-server", "outcome" : true},{ "outcome" : true }]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Check the status of the WildFly service using the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ssh root@10.0.148.43 systemctl status wildfly &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In the following output, we can see the WildFly service is running without any errors:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;● wildfly.service - JBoss EAP (standalone mode) Loaded: loaded (/usr/lib/systemd/system/wildfly.service; enabled; vendor preset: disabled) Active: active (running) since Thu 2023-03-02 18:02:44 EST; 4 days ago Main PID: 52667 (standalone.sh) Tasks: 45 (limit: 23417) Memory: 263.6M CGroup: /system.slice/wildfly.service ├─52667 /bin/sh /opt/wildfly-26.0.0.Final/bin/standalone.sh -c wildfly.xml -b 0.0.0.0 -Djboss.server.config.dir=/opt/wildfly&gt; └─52741 java -D[Standalone] -server -Xms64m -Xmx512m -XX:MetaspaceSize=96M -XX:MaxMetaspaceSize=256m -Djava.net.preferIPv4St&gt; Mar 02 18:02:47 wildfly-0 standalone.sh[52741]: 18:02:47,802 INFO [org.jboss.modcluster] (ServerService Thread Pool -- 84) MODCLUSTER0&gt; Mar 02 18:02:47 wildfly-0 standalone.sh[52741]: 18:02:47,829 INFO [org.wildfly.extension.undertow] (MSC service thread 1-1) WFLYUT0006&gt; Mar 02 18:02:47 wildfly-0 standalone.sh[52741]: 18:02:47,864 INFO [org.jboss.as.connector.subsystems.datasources] (MSC service thread &gt; Mar 02 18:02:47 wildfly-0 standalone.sh[52741]: 18:02:47,953 INFO [org.jboss.as.patching] (MSC service thread 1-2) WFLYPAT0050: WildFl&gt; Mar 02 18:02:47 wildfly-0 standalone.sh[52741]: 18:02:47,988 INFO [org.jboss.as.server.deployment.scanner] (MSC service thread 1-1) WF&gt; Mar 02 18:02:48 wildfly-0 standalone.sh[52741]: 18:02:48,002 INFO [org.jboss.ws.common.management] (MSC service thread 1-3) JBWS022052&gt; Mar 02 18:02:48 wildfly-0 standalone.sh[52741]: 18:02:48,179 INFO [org.jboss.as.server] (Controller Boot Thread) WFLYSRV0212: Resuming&gt; Mar 02 18:02:48 wildfly-0 standalone.sh[52741]: 18:02:48,182 INFO [org.jboss.as] (Controller Boot Thread) WFLYSRV0025: WildFly Full 26&gt; Mar 02 18:02:48 wildfly-0 standalone.sh[52741]: 18:02:48,183 INFO [org.jboss.as] (Controller Boot Thread) WFLYSRV0060: Http management&gt; Mar 02 18:02:48 wildfly-0 standalone.sh[52741]: 18:02:48,183 INFO [org.jboss.as] (Controller Boot Thread) WFLYSRV0051: Admin console l&gt; lines 1-20/20 (END)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;We can also validate the instance using our &lt;a href="https://github.com/ansible-middleware/wildfly-cluster-demo/blob/main/validate.yml"&gt;validate.yml&lt;/a&gt;. This will check if the instance is running and if the WildFly port is accessible for use.&lt;/p&gt; &lt;h2&gt;Explore other tutorials and resources&lt;/h2&gt; &lt;p&gt;In this tutorial, we demonstrated how to set up and provision an instance of WildFly using the Ansible Content Collections &lt;span&gt;for WildFly. We can also deploy JBoss EAP instead of the open-source WildFly using the same collection. For more information on deploying JBoss EAP refer to &lt;/span&gt;&lt;a href="https://developers.redhat.com/articles/2022/02/08/automate-and-deploy-jboss-eap-cluster-ansible#"&gt;Automate and deploy a JBoss EAP cluster with Ansible&lt;/a&gt;&lt;span&gt;. To deploy WildFly or JBoss EAP on multiple instances, you can refer to our &lt;/span&gt;&lt;a href="https://github.com/ansible-middleware/wildfly-cluster-demo"&gt;wildfly-cluster-demo&lt;/a&gt;&lt;span&gt;. &lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;For a more complex scenario, check out our &lt;/span&gt;&lt;a href="https://github.com/ansible-middleware/flange-demo"&gt;Flange project demo&lt;/a&gt;&lt;span&gt;, which uses the JBoss EAP, &lt;/span&gt;&lt;a href="https://access.redhat.com/products/red-hat-single-sign-on"&gt;Red Hat Single Sign-On&lt;/a&gt;&lt;span&gt;, and &lt;/span&gt;&lt;a href="https://developers.redhat.com/products/datagrid/overview"&gt;Red Hat Data Grid&lt;/a&gt;&lt;span&gt; as a cache and &lt;/span&gt;&lt;a href="https://access.redhat.com/collections/red-hat-jboss-core-services-collection"&gt;Red Hat Middleware Core Services Collection&lt;/a&gt;&lt;span&gt; as a load balancer. Also, our &lt;/span&gt;&lt;a href="https://console.redhat.com/ansible/automation-hub/repo/published/redhat/jboss_eap/"&gt;redhat.jboss_eap&lt;/a&gt;&lt;span&gt; collection is available on Ansible automation hub. Note that this collection is a Beta release and for &lt;/span&gt;&lt;a href="https://access.redhat.com/support/offerings/techpreview"&gt;Technical Preview&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;You can check out the other collections and demos within the GitHub organization: &lt;a href="https://github.com/ansible-middleware"&gt;ansible-middleware&lt;/a&gt; and the &lt;a href="https://ansiblemiddleware.com"&gt;Middleware Automation Collections&lt;/a&gt; &lt;span&gt;website.&lt;/span&gt;&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/03/14/tutorial-middleware-automation-collections" title="A tutorial on Middleware Automation Collections"&gt;A tutorial on Middleware Automation Collections&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Harsha Cherukuri</dc:creator><dc:date>2023-03-14T07:00:00Z</dc:date></entry><entry><title type="html">Quarkus Newsletter #30 - March</title><link rel="alternate" href="https://quarkus.io/blog/quarkus-newsletter-30/" /><author><name>James Cobb</name></author><id>https://quarkus.io/blog/quarkus-newsletter-30/</id><updated>2023-03-14T00:00:00Z</updated><content type="html">It’s time for the March newletter so you can read the latest articles, blogs and insights on Quarkus. Get a deeper understanding of what developers can expect in the final version 3.0 with this InfoQ article "Road to Quarkus 3: Bets on the Flow API for Mutiny 2.0, Updates to...</content><dc:creator>James Cobb</dc:creator></entry><entry><title type="html">Serverless Workflow VSCode Editor support to Open API and Async API</title><link rel="alternate" href="https://blog.kie.org/2023/03/serverless-workflow-vscode-editor-support-to-open-api-and-async-api.html" /><author><name>Saravana Balaji</name></author><id>https://blog.kie.org/2023/03/serverless-workflow-vscode-editor-support-to-open-api-and-async-api.html</id><updated>2023-03-13T20:08:08Z</updated><content type="html">In the previous we saw how one can register OpenAPI endpoints and AsyncAPI channels in Service registry and pass them as functions. Also we saw steps to use those functions in Serverless Logic Web Tools via Service Catalog Explorer’s autocomplete feature. This article explains how this same feature works in Kogito Serverless Workflow VS Code extension. In this extension, the API specifications can be uploaded via external registries, or you can create a folder named specs within the project and place the specification files there. You can look at the repository for examples of workflows and specification files. SERVICE CATALOG IN SERVERLESS WORKFLOW VSCODE EXTENSION To proceed further, you will need and the Kogito Serverless Workflow VS Code extension. There are several ways to download and install Kogito Serverless Workflow VS Code extension 1. You can download from the 2. Click on the Extensions icon in the Activity Bar on the side of VS Code, search and install. * 3. Launch VS Code Quick Open (Ctrl+P), paste the following commands, and press enter: * ext install redhat.vscode-extension-serverless-workflow-editor Before proceeding with the project, let us set up the service registries. Some of the features in the Serverless Workflow Editor require integration with Red Hat OpenShift Application and Data Services. Here, uploading API specifications to a service registry requires this integration. Now, in the Red Hat OpenShift application and Data Services, let us create a service registry. CREATING A SERVICE REGISTRY You can create or use a Service Registry instance from your Red Hat OpenShift Application and Data Services console and add the Service Registry to Serverless Logic Web Tools. Prerequisites * You have access to the Red Hat OpenShift Application and Data Services console. Procedure 1. To create a Service Registry instance in the Red Hat Openshift Application and Data Services console, perform the following steps: 1. Go to the. 2. Click the “Create Service Registry Instance” button. 2. Enter a Service Registry instance name in the Create a Service Registry Instance window and click Create. Click on the menu in the top-right corner of the screen. 3. Click Connection. 1. A drawer opens, containing the required connection and authentication information. 2. Copy the value of the Core Registry API. 4. If you already have a Service Registry, find the value of the Core Registry API of your Service Registry. UPLOAD THE API SPECIFICATION: Once you have the Service registry created, you are set to upload the API specification file, which could be an Open API or an Async API. Procedure: 1. On the OpenShift Application Console, go to the Service Registry instance that you created. 2. Click the Upload Artifact button, and a modal window opens. 3. On the modal, enter the group and artifacts ID, which are mandatory fields. 4. You can choose type from the dropdown menu, or you can leave the default option Auto-Detect alone. 5. In the artifact section, you can browse or drag and drop the API specification file, or you can also copy-paste the content directly into the text area. 6. Finally, click “upload.” CONFIGURE YOUR VISUAL STUDIO CODE Open the Command Palette: * Hit F1 or select from the menu View &gt; Command Palette… Type Pref and select Preferences: Open User Settings (JSON) Add the following configuration key and close it: "kogito.swf.serviceRegistries": { "registries": [ { "authProvider": "red-hat-account", "name": &lt;Provide your registry name&gt;, "url": &lt;Paste Core Registry API copied from console&gt; } ] } Against the property authProvider you can provide either none or ‘red-hat-account’. If you choose ‘red-hat-account’, then you will need to install and provide authentication, steps are as follows. ACCESSING THE SERVICE CATALOG IN VSCODE EXTENSION When you have all the prerequisites ready, it is possible to create a workflow and try the Service Catalog feature. You can create an empty file with a filename and extension ‘.sw.json’ or ‘.sw.yaml’. Open the created document. You can click on the Create a Serverless Workflow option to generate a basic template workflow. Just above the functions property, there will be a Setup Service Registries option. When you click, it will take you through the Red Hat account login screen where you can enter your credentials. Post login you can click on the Refresh Service Registries option to refresh the editor. You will find the Add Function option clicking on it, a side widget containing a list of function suggestions will appear. These functions are extracted from the API specification files that you uploaded on the Red Hat OpenShift Application Console. When you select a particular function, it will automatically generate auto-filled name, operation, and type properties. With this we have seen how you can register OpenAPI endpoints and AsyncAPI channels through Service registries and pass them as functions to the editor. Thats all for now, Stay tuned for more exciting new features on Kogito Serverless Workflow editors. The post appeared first on .</content><dc:creator>Saravana Balaji</dc:creator></entry><entry><title>How to use automation controller to install MS SQL</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/03/13/how-use-automation-controller-install-ms-sql" /><author><name>Nagesh Rathod</name></author><id>2d761366-b417-4710-bdf3-b24bd48a6b92</id><updated>2023-03-13T07:00:00Z</updated><published>2023-03-13T07:00:00Z</published><summary type="html">&lt;p&gt;The purpose of this article is to demonstrate how to create an execution environment with custom dependencies and how to execute Ansible Playbooks using the automation controller's GUI, a component of Red Hat Ansible Automation Platform. For this article, we will use Ansible Roles to install Microsoft SQL on Red Hat Enterprise Linux 8.&lt;/p&gt; &lt;p&gt;Make sure you have the &lt;a href="https://developers.redhat.com/products/ansible/overview"&gt;&lt;u&gt;Ansible Automation Platform&lt;/u&gt;&lt;/a&gt; installed on your machine before you begin. For more information about Ansible Automation Platform installation, please refer to our previous article, &lt;a href="https://developers.redhat.com/articles/2023/01/01/how-install-red-hat-ansible-automation-platform-rhel-9#"&gt;How to install Red Hat Ansible Automation Platform on RHEL 9&lt;/a&gt;. Follow these five steps to complete this demonstration:&lt;/p&gt; &lt;h2&gt;Step 1. Setting up the automation execution environment&lt;/h2&gt; &lt;p&gt;Automation execution environments provide a defined, consistent, and portable environment for executing automation jobs. Unlike legacy virtual environments, automation execution environments are Linux container images that make it possible to incorporate system-level dependencies and collection-based content. Each automation execution environment allows you to have a customized image to run jobs, and each of them contains only what you need when running the job.&lt;/p&gt; &lt;p&gt;There are dependencies for the automation execution environment, such as Python 3 and Podman. Make sure these tools are installed. We have provided instructions for installing and using Podman in this &lt;a href="https://developers.redhat.com/videos/youtube/bJDI_QuXeCE"&gt;video&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Before you can complete any of the following tasks, you must create a registry &lt;a href="https://access.redhat.com/terms-based-registry/"&gt;&lt;u&gt;service account&lt;/u&gt;&lt;/a&gt;. To log in, open up your terminal and type the following commands:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;podman login registry.redhat.io Username: {REGISTRY-SERVICE-ACCOUNT-USERNAME} Password: {REGISTRY-SERVICE-ACCOUNT-PASSWORD} Login Succeeded!&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Once we are successfully logged in, we need to create a container image by using a &lt;strong&gt;Containerfile&lt;/strong&gt; containing the following context:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;​​​​​​​FROM registry.redhat.io/ansible-automation-platform-22/ee-29-rhel8:latest RUN ansible-galaxy collection install microsoft.sql&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To build an image using podman enter the following:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;​​​​​​​podman build -t &lt;image-name&gt;.&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The image should be pushed into the container image registry. Log in to the private container image registry using the command 'podman login' before pushing.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;podman push &lt;image-name&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Add the image name in the automation execution environment, as shown in Figure 1.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/1_0.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/1_0.png?itok=mgnWbc_Q" width="600" height="293" alt="The edit details section of the Execution Environment page in Ansible Automation Platform." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: The Execution Environment page.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt; &lt;/p&gt; &lt;h2&gt;Step​​​​​​​ 2. Set up the inventory&lt;/h2&gt; &lt;p&gt;An inventory is a collection of hosts against which jobs may be launched. To create inventory in Ansible Automation Platform please follow these steps and refer to Figure 2:&lt;/p&gt; &lt;ol&gt;&lt;li aria-level="1"&gt;Select the inventory from the left menu.&lt;/li&gt; &lt;li aria-level="1"&gt;Click on &lt;strong&gt;add&lt;/strong&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;Select &lt;strong&gt;add inventory&lt;/strong&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;Give a name to the inventory and save it.&lt;/li&gt; &lt;li aria-level="1"&gt;Select the hosts from inventories and click &lt;strong&gt;add hosts&lt;/strong&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;Give the targeted server IP or name and save it.&lt;/li&gt; &lt;/ol&gt;&lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/2_4.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/2_4.png?itok=mWv_pWQN" width="600" height="217" alt="The Inventory page in Ansible Automation Platform." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2: The Inventory page.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt; &lt;/p&gt; &lt;h2&gt;Step 3. Set up the credentials&lt;/h2&gt; &lt;p&gt;To connect with the target server, we need credentials such as username, password, or ssh key. By using credentials, we can pass the required credentials during the playbook execution.&lt;/p&gt; &lt;p&gt;Follow these steps and refer to Figure 3:&lt;/p&gt; &lt;ol&gt;&lt;li aria-level="1"&gt;Select the credentials from the left menu.&lt;/li&gt; &lt;li aria-level="1"&gt;Click on new credentials and select Machine credentials type.&lt;/li&gt; &lt;li aria-level="1"&gt;Add your username, password, or ssh key in the corresponding fields.&lt;/li&gt; &lt;/ol&gt;&lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/3_6.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/3_6.png?itok=QJ4O8qnN" width="600" height="219" alt="The credentials page in Ansible Automation Platform." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 3: The credentials page.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt; &lt;/p&gt; &lt;h2&gt;Step 4. Configuring a project&lt;/h2&gt; &lt;p&gt;A project is a logical collection of Ansible Playbooks represented in the controller. You can manage playbooks and playbook directories on your controller server either manually or by using a source code management (SCM) system such as Git, Subversion, or Mercurial supported by the controller.&lt;/p&gt; &lt;p&gt;Follow these steps to create a project and refer to Figure 4:&lt;/p&gt; &lt;ol&gt;&lt;li aria-level="1"&gt;Create a new project for our git repository from the left menu.&lt;/li&gt; &lt;li aria-level="1"&gt;Click on the &lt;strong&gt;+&lt;/strong&gt; icon in the right corner.&lt;/li&gt; &lt;li aria-level="1"&gt;Give the project a name.&lt;/li&gt; &lt;li aria-level="1"&gt;Select your organization (or choose &lt;strong&gt;Default&lt;/strong&gt;).&lt;/li&gt; &lt;li aria-level="1"&gt;Select the SCM TYPE (GIT in our case).&lt;/li&gt; &lt;li aria-level="1"&gt;Add RESOURCE DETAILS &lt;ul&gt;&lt;li aria-level="2"&gt;SCM &lt;a href="https://github.com/redhat-developer-demos/MicrosoftSQL-AAP-on-RHEL"&gt;&lt;u&gt;URL&lt;/u&gt;&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="2"&gt;SCM BRANCH(main)&lt;/li&gt; &lt;li aria-level="2"&gt;SCM CREDENTIAL&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li aria-level="2"&gt;Save it.&lt;/li&gt; &lt;/ol&gt;&lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/4_3.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/4_3.png?itok=RGZpqYlc" width="600" height="298" alt="The Project page of Ansible Automation Platform." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 4: The Project page.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt; &lt;/p&gt; &lt;h2&gt;Step 5. Configuring templates&lt;/h2&gt; &lt;p&gt;&lt;a href="https://docs.ansible.com/automation-controller/latest/html/userguide/glossary.html#term-Job-Template"&gt;&lt;u&gt;Templates&lt;/u&gt;&lt;/a&gt; define and set parameters for running jobs. A template is more like a blueprint where all of the dependencies are defined, such as inventory, projects, credentials, etc.&lt;/p&gt; &lt;p&gt;Follow these steps to create a template to execute the job for us (see Figure 5):&lt;/p&gt; &lt;ol&gt;&lt;li aria-level="1"&gt;From the left menu, select templates and create a new template.&lt;/li&gt; &lt;li aria-level="1"&gt;Click on + icon from the right corner and select the Job template.&lt;/li&gt; &lt;li aria-level="1"&gt;Give the template a name.&lt;/li&gt; &lt;li aria-level="1"&gt;Select the project and playbook you want to run in the template.&lt;/li&gt; &lt;li aria-level="1"&gt;Select &lt;a href="https://github.com/redhat-developer-demos/MicrosoftSQL-AAP-on-RHEL/blob/main/microsoft_sql_playbook.yaml"&gt;microsoft_sql_playbook.yaml&lt;/a&gt; playbook.&lt;/li&gt; &lt;li aria-level="1"&gt;Select the execution environment which you created previously.&lt;/li&gt; &lt;/ol&gt;&lt;pre&gt; &lt;code class="language-bash"&gt;--- - hosts: dev   collections:   - microsoft.sql   vars:     mssql_accept_microsoft_odbc_driver_17_for_sql_server_eula: true     mssql_accept_microsoft_cli_utilities_for_sql_server_eula: true     mssql_accept_microsoft_sql_server_standard_eula: true     mssql_password: "YourP@ssw0rd"     mssql_edition: Evaluation     mssql_enable_sql_agent: true     mssql_install_fts: true     mssql_install_powershell: true     mssql_tune_for_fua_storage: true   roles:     - microsoft.sql.server​&lt;/code&gt;&lt;/pre&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/5_5.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/5_5.png?itok=uRgIOScv" width="600" height="297" alt="The templates page in Ansible Automation Platform." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 5: The Templates page.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p class="Indent1"&gt;7. ​​​​​​​Launch it (Figure 6).&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/6_2.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/6_2.jpg?itok=5dhT1dcv" width="600" height="298" alt="After launching, this page shows the output of a successful installation of MicrosoftSQL server." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 6: After launching, a successful installation of MicrosoftSQL server.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt; &lt;/p&gt; &lt;h2&gt;Continue your automation journey with Ansible&lt;/h2&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/products/ansible/getting-started"&gt;&lt;u&gt;Get started&lt;/u&gt;&lt;/a&gt; with the Ansible Automation Platform by exploring &lt;a href="https://developers.redhat.com/products/ansible/getting-started"&gt;interactive labs&lt;/a&gt;. Ansible Automation Platform is also available as a managed offering on&lt;a href="https://www.redhat.com/en/technologies/management/ansible/azure"&gt;&lt;u&gt; Microsoft Azure&lt;/u&gt;&lt;/a&gt; and as a self-managed offering on &lt;a href="https://www.redhat.com/en/technologies/management/ansible/aws"&gt;&lt;u&gt;AWS&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/03/13/how-use-automation-controller-install-ms-sql" title="How to use automation controller to install MS SQL"&gt;How to use automation controller to install MS SQL&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Nagesh Rathod</dc:creator><dc:date>2023-03-13T07:00:00Z</dc:date></entry><entry><title type="html">Infinispan 14.0.7.Final</title><link rel="alternate" href="https://infinispan.org/blog/2023/03/13/infinispan-14" /><author><name>Tristan Tarrant</name></author><id>https://infinispan.org/blog/2023/03/13/infinispan-14</id><updated>2023-03-13T00:00:00Z</updated><content type="html">We rarely do announcements for micro-releases, but 14.0.7.Final is a bit special, because it finally adds support for Spring 6 and Spring Boot 3. SPRING FRAMEWORK 6 AND SPRING BOOT 3 We now ship components to support Spring Framework 6 and Spring Boot 3: &lt;dependency&gt; &lt;groupId&gt;org.infinispan&lt;/groupId&gt; &lt;artifactId&gt;infinispan-spring-boot3-starter-embedded&lt;/artifactId&gt; &lt;version&gt;14.0.7.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.infinispan&lt;/groupId&gt; &lt;artifactId&gt;infinispan-spring-boot3-starter-remote&lt;/artifactId&gt; &lt;version&gt;14.0.7.Final&lt;/version&gt; &lt;/dependency&gt; IMPORTANT SIFS FIXES This release also includes very important fixes to the Soft-Index File Store (SIFS), which is our default file-store implementation: if you use it for your persistent caches you should really upgrade ! RELEASE NOTES FEATURE REQUEST * * BUG * * * * * * * * * * * * * * * * * * * * * * * * TASK * * * COMPONENT UPGRADE * * * * * * * * ENHANCEMENT * * * * * * * RELEASE NOTES You can look at the to see what has changed since our latest CR.] Get them from our .]</content><dc:creator>Tristan Tarrant</dc:creator></entry><entry><title type="html">How to use Keycloak Admin REST API</title><link rel="alternate" href="http://www.mastertheboss.com/keycloak/how-to-use-keycloak-admin-rest-api/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/keycloak/how-to-use-keycloak-admin-rest-api/</id><updated>2023-03-10T16:42:44Z</updated><content type="html">The Keycloak REST Admin API is a Web service Endpoint that allows you to manage Keycloak programmatically. It provides endpoints for creating, updating, and deleting Keycloak entities such as users, groups, clients, roles, and realms. You can use any programming language that supports HTTP requests to interact with the API. Pre-requisite: If you are new ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">What&amp;#8217;s new in Dashbuilder 0.27.0?</title><link rel="alternate" href="https://blog.kie.org/2023/03/whats-new-in-dashbuilder-0-27-0.html" /><author><name>William Siqueira</name></author><id>https://blog.kie.org/2023/03/whats-new-in-dashbuilder-0-27-0.html</id><updated>2023-03-10T11:40:46Z</updated><content type="html">was released yesterday (March 8th, 2023) and it comes with very interesting new features. Let’s explore the new release in this post! NEW SAMPLES SCREEN A new sample screen allows Dashbuilder to render dashboards from a remote or local repository. A sample is a dashboard that users can try without installing on their Dashbuilder. The samples’ screen can be accessed when no dashboard is available. You can see the samples’ screen in action in our , but soon you will hear about it because it will be part of . AUTOCOMPLETE AND SYNTAX CHECK Dashbuilder now supports autocomplete and syntax verification in and ! CONTROLLED CONCURRENT DATASET ACCESS Now dashbuilder unifies HTTP requests when multiple displayers try to access the same dataset. In practice if you have X displayers on a page, it used to result in X HTTP requests, now Dashbuilder makes a single request for all displayers. BUG FIXES Fixed navigation between dashboards: It is possible to have more than one dashboard on the same dashbuilder installation. The navigation between dashboards now refreshes the page, making it easier to navigate between dashboards; Dark mode in components: Victory Charts and Table external components now supports dark mode; Dark mode in VSCode: Dark mode is now fixed in VSCode extension CONCLUSION In this post we shared the new features and improvements in Dashbuilder 0.27.0! Stay tuned for more dashbuilder news. The post appeared first on .</content><dc:creator>William Siqueira</dc:creator></entry></feed>
